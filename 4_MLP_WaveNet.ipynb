{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "81802f6c",
   "metadata": {},
   "source": [
    "## **Implementing WaveNet: A Generative Model for Raw Audio (Adapted for Word Generation)**\n",
    "\n",
    "* WaveNet is originally a **generative model for raw audio**.\n",
    "  In this notebook, I will adapt its underlying **architecture** for our **word generation model**, since the core design principles are similar.\n",
    "\n",
    "* The goal is to **improve our baseline model’s architecture** by aligning it more closely with the **WaveNet-inspired approach** discussed in the research paper \"https://arxiv.org/pdf/1609.03499\".\n",
    "\n",
    "---\n",
    "\n",
    "### **Baseline Model (Previous Architecture)**\n",
    "\n",
    "```python\n",
    "model_2 = Sequential([\n",
    "    Embeddings(vocab_size, n_embeddings),\n",
    "    Flatten(),\n",
    "    Linear(in_features, out_features),  BatchNorm1d(out_features), Tanh(),\n",
    "    Linear(out_features, out_features), BatchNorm1d(out_features), Tanh(),\n",
    "    Linear(out_features, out_features), BatchNorm1d(out_features), Tanh(),\n",
    "    Linear(out_features, out_features), BatchNorm1d(out_features), Tanh(),\n",
    "    Linear(out_features, out_features), BatchNorm1d(out_features), Tanh(),\n",
    "    Linear(out_features, out_features), BatchNorm1d(out_features), Tanh(),\n",
    "    Linear(out_features, vocab_size)\n",
    "])\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **Upgrading Towards a WaveNet-like Model**\n",
    "\n",
    "In this notebook, I will move beyond the **basic Neural Network + Batch Normalization setup** and introduce a **WaveNet-inspired architecture**.\n",
    "\n",
    "Unlike the baseline model, where squashing/non-linear transformations occur **suddenly**, the WaveNet approach allows features to be **progressively compressed and transformed** through **causal and dilated convolutions**, capturing **hierarchical patterns** in a smoother, more structured manner.\n",
    "\n",
    "---\n",
    "\n",
    "### **Advantages of WaveNet over Plain Neural Networks**\n",
    "\n",
    "1. **Better Long-Term Dependency Modeling**\n",
    "\n",
    "   * WaveNet’s **dilated convolutions** can capture patterns over much longer contexts without requiring extremely deep layers.\n",
    "\n",
    "2. **Smoother Feature Extraction**\n",
    "\n",
    "   * Instead of forcing representations to collapse quickly, WaveNet progressively refines them, leading to more stable and expressive outputs.\n",
    "\n",
    "3. **Improved Generative Quality**\n",
    "\n",
    "   * The autoregressive setup enables WaveNet to generate highly realistic sequences (in audio or text), compared to the sometimes rigid outputs of standard feedforward networks.\n",
    "\n",
    "4. **Scalability**\n",
    "\n",
    "   * Easier to parallelize compared to recurrent models like RNNs or LSTMs, while still capturing temporal dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b2e17b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b3fe40e",
   "metadata": {},
   "source": [
    "# Laoding dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "435da4f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all the words from the '.txt' file\n",
    "words = open('names.txt', mode = 'r', encoding='utf-8').read().splitlines()\n",
    "words[:10]\n",
    "\n",
    "# Encoder and Decoder\n",
    "chars = sorted(list(set(''.join(words))))\n",
    "stoi = {c:i+1 for i, c in enumerate(chars)}\n",
    "stoi['.'] = 0\n",
    "itos = {i:c for c, i in stoi.items()}\n",
    "\n",
    "# Generate train, test and validation Dataset\n",
    "def generate_dataset(words, block_size):\n",
    "    x, y = [], []\n",
    "    for w in words:\n",
    "        # print(w)\n",
    "        context = [0] * block_size\n",
    "        for ch in w + '.':\n",
    "            idx = stoi[ch]\n",
    "            x.append(context)\n",
    "            y.append(idx)\n",
    "            # print(f\"{''.join([itos[i] for i in context])} --> {itos[idx]}\")\n",
    "            context = context[1:] + [idx]\n",
    "    x, y = torch.tensor(x), torch.tensor(y)\n",
    "    return x, y\n",
    "\n",
    "def get_split(data, train_split: float, test_split: float, val_split: float, block_size: int):\n",
    "    import random\n",
    "    random.seed(42)\n",
    "\n",
    "    if (train_split + test_split + val_split) != 1:\n",
    "        raise ValueError(\"All splits must sum to 100% of the data\")\n",
    "    else: \n",
    "        random.shuffle(data)\n",
    "        n1 = int(train_split* len(data))\n",
    "        n2 = int((train_split + val_split) * len(data))\n",
    "        x_train, y_train = generate_dataset(data[:n1], block_size)\n",
    "        x_val, y_val = generate_dataset(data[n1:n2], block_size)\n",
    "        x_test, y_test = generate_dataset(data[n2:], block_size)\n",
    "\n",
    "        return x_train, y_train, x_val, y_val, x_test, y_test\n",
    "\n",
    "x_train, y_train, x_val, y_val, x_test, y_test = get_split(data = words, train_split = 0.8, test_split = 0.1, val_split = 0.1, block_size = 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e5c104e",
   "metadata": {},
   "source": [
    "## Defining the Framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "093f745b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Embeddings:\n",
    "    def __init__(self, embd_dim, n_classes):\n",
    "        self.embd_dim = embd_dim\n",
    "        self.n_classes = n_classes\n",
    "        self.embd_matrix = torch.nn.Parameter(torch.randn(self.n_classes, self.embd_dim, requires_grad=True))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.embd_matrix[x]\n",
    "    \n",
    "    def parameters(self):\n",
    "        return [self.embd_matrix]\n",
    "    \n",
    "    def __call__(self, x):\n",
    "        return self.forward(x)\n",
    "    \n",
    "    def to(self, device):\n",
    "        self.embd_matrix = torch.nn.Parameter(self.embd_matrix.to(device))\n",
    "        return self\n",
    "\n",
    "\n",
    "class Linear:\n",
    "    def __init__(self, *, in_features, out_features):\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.weight = torch.nn.Parameter(torch.randn(in_features, out_features))\n",
    "        self.bias = torch.nn.Parameter(torch.randn(out_features,))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return x @ self.weight + self.bias\n",
    "    \n",
    "    def __call__(self, x):\n",
    "        return self.forward(x)\n",
    "    \n",
    "    def parameters(self):\n",
    "        return [self.weight] + [self.bias]\n",
    "    \n",
    "    def to(self, device):\n",
    "        self.weight = torch.nn.Parameter(self.weight.to(device))\n",
    "        self.bias = torch.nn.Parameter(self.bias.to(device))\n",
    "        return self\n",
    "\n",
    "\n",
    "class Flatten:\n",
    "    def forward(self, x):\n",
    "        return x.view(x.shape[0], -1)\n",
    "    \n",
    "    def __call__(self, x):\n",
    "        return self.forward(x)\n",
    "    \n",
    "    def parameters(self):\n",
    "        return []\n",
    "    \n",
    "    def to(self, device):\n",
    "        return self\n",
    "\n",
    "\n",
    "class Sequential:\n",
    "    def __init__(self, layers):\n",
    "        self.layers = layers\n",
    "        # Model Configuration\n",
    "        self.embd_dim = None\n",
    "        self.n_classes = None\n",
    "        self.in_features = None\n",
    "        self.out_features = None\n",
    "        for layer in self.layers:\n",
    "            if isinstance(layer, Embeddings):\n",
    "                self.embd_dim = layer.embd_dim\n",
    "                self.n_classes = layer.n_classes\n",
    "                break\n",
    "        for layer in self.layers:\n",
    "            if isinstance(layer, Linear):\n",
    "                self.in_features = layer.in_features\n",
    "                self.out_features = layer.out_features\n",
    "                break\n",
    "    \n",
    "    def forward(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        return x\n",
    "    \n",
    "    def __call__(self, x):\n",
    "        return self.forward(x)\n",
    "    \n",
    "    def parameters(self):\n",
    "        return [p for layer in self.layers for p in layer.parameters()]\n",
    "    \n",
    "    def to(self, device):\n",
    "        for layer in self.layers:\n",
    "            layer.to(device)\n",
    "        return self\n",
    "\n",
    "\n",
    "class Tanh:\n",
    "    def forward(self, x):\n",
    "        return torch.tanh(x)\n",
    "    \n",
    "    def __call__(self, x):\n",
    "        return self.forward(x)\n",
    "    \n",
    "    def parameters(self):\n",
    "        return []\n",
    "    \n",
    "    def to(self, device):\n",
    "        return self\n",
    "\n",
    "class ReLU:\n",
    "    def forward(self, x):\n",
    "        return torch.relu(x)\n",
    "    \n",
    "    def __call__(self, x):\n",
    "        return self.forward(x)\n",
    "    \n",
    "    def parameters(self):\n",
    "        return []\n",
    "    \n",
    "    def to(self, device):\n",
    "        return self\n",
    "\n",
    "\n",
    "class Softmax:\n",
    "    def forward(self, logits):\n",
    "        exp_logits = torch.exp(logits)\n",
    "        probs = exp_logits / exp_logits.sum(dim = 1, keepdim = True)\n",
    "        return probs\n",
    "    \n",
    "    def __call__(self, logits):\n",
    "        return self.forward(logits)\n",
    "    \n",
    "    def parameters(self):\n",
    "        return []\n",
    "    \n",
    "    def to(self, device):\n",
    "        return self\n",
    "\n",
    "\n",
    "class CrossEntropyLoss:\n",
    "    def forward(self, logits, y_true):\n",
    "        softmax = Softmax()\n",
    "        probs = softmax(logits)\n",
    "        loss = -(probs[torch.arange(0, len(probs)), y_true].log().mean())\n",
    "        return loss\n",
    "    \n",
    "    def __call__(self, logits, y_true):\n",
    "        return self.forward(logits, y_true)\n",
    "    \n",
    "    def parameters(self):\n",
    "        return []\n",
    "\n",
    "class LayerNorm1d:\n",
    "    def __init__(self, in_features, eps = 1e-8):\n",
    "        self.in_features = in_features\n",
    "        self.gamma = torch.nn.Parameter(torch.ones(1, self.in_features))\n",
    "        self.beta = torch.nn.Parameter(torch.zeros(1, self.in_features))\n",
    "        self.eps = eps\n",
    "    \n",
    "    def forward(self, x):\n",
    "        mean = x.mean(dim = -1, keepdim  = True)\n",
    "        std = x.std(dim = -1, keepdim  = True)\n",
    "        x_norm = ((x - mean) / (std + self.eps))\n",
    "        return x_norm * self.gamma + self.beta # here * is Hadamard Multiplication (element-wise) multiplication\n",
    "    \n",
    "    def parameters(self):\n",
    "        return [self.gamma] + [self.beta]\n",
    "    \n",
    "    def to(self, device):\n",
    "        self.gamma = torch.nn.Parameter(self.gamma.to(device))\n",
    "        self.beta = torch.nn.Parameter(self.beta.to(device))\n",
    "        return self\n",
    "    \n",
    "    def __call__(self, x):\n",
    "        return self.forward(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eb20b6b",
   "metadata": {},
   "source": [
    "## Class for registering the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e68faf66",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RegisterModel:\n",
    "    def __init__(self, model_name, model_version, model, device):\n",
    "        self.model_name = model_name\n",
    "        self.model_version = model_version\n",
    "        self.model = model\n",
    "        self.layers = self.model.layers\n",
    "        self.embd_dim = self.model.embd_dim\n",
    "        self.n_classes = self.model.n_classes\n",
    "        self.in_features = self.model.in_features\n",
    "        self.out_features = self.model.out_features\n",
    "        self.loss_fn = CrossEntropyLoss()\n",
    "        self.parameters = self.model.parameters()\n",
    "        self.device = device\n",
    "        self.to(device)\n",
    "        self.n_parameters = sum([p.nelement() for p in self.parameters])\n",
    "        print(f\"Model registered with {self.n_parameters} Parameters\")\n",
    "    \n",
    "    def train(self, x, y, epochs, lr):\n",
    "        batch_size = 512\n",
    "        self.summary(epochs, lr)\n",
    "        print(\"-\" * 100)\n",
    "\n",
    "        initial_lr = lr\n",
    "        \n",
    "        for epoch in range(epochs):\n",
    "            # Learning rate decay\n",
    "            lr = initial_lr * (0.95 ** (epoch // 200))\n",
    "\n",
    "            total_loss = 0\n",
    "            \n",
    "            for i in range(0, len(x), batch_size):\n",
    "                xb = x[i:i + batch_size]\n",
    "                yb = y[i:i + batch_size]\n",
    "\n",
    "                logits = self.model(xb)\n",
    "                loss = self.loss_fn(logits=logits, y_true=yb)\n",
    "                total_loss += loss.item()\n",
    "\n",
    "                # Reset gradients\n",
    "                for p in self.model.parameters():\n",
    "                    p.grad = None\n",
    "\n",
    "                loss.backward()\n",
    "\n",
    "                # Manual SGD update\n",
    "                for p in self.model.parameters():\n",
    "                    p.data -= lr * p.grad\n",
    "\n",
    "            if epoch % 50 == 0:\n",
    "                avg_loss = total_loss / (len(x) // batch_size)\n",
    "                print(f\"Epoch {epoch}/{epochs} | Loss: {avg_loss:.4f} | lr={lr:.5f}\")\n",
    "\n",
    "                \n",
    "    def to(self, device):\n",
    "        self.model.to(device)\n",
    "        return self\n",
    "    \n",
    "    def __call__(self, x, y, epochs, lr):\n",
    "        return self.train(x, y, epochs, lr)\n",
    "    \n",
    "    def summary(self, epochs, lr):\n",
    "        print(f\"Training {self.model_name} | {self.model_version} | Epochs = {epochs} | lr = {lr} | device = {self.device}\")\n",
    "\n",
    "        print(\"\\n\" + \"=\"*90)\n",
    "        print(\"Training Configuration Summary\")\n",
    "        print(\"=\"*90)\n",
    "        print(f\"Model Name        : {self.model_name}\")\n",
    "        print(f\"Model Version     : {self.model_version}\")\n",
    "        print(f\"Device            : {self.device}\")\n",
    "        print(f\"Epochs            : {epochs}\")\n",
    "        print(f\"Learning Rate     : {lr}\")\n",
    "        print(\"-\"*90)\n",
    "        print(\"Model Hyperparameters:\")\n",
    "        print(f\"  ├─ Embedding Dimension : {self.embd_dim}\")\n",
    "        print(f\"  ├─ Number of Classes   : {self.n_classes}\")\n",
    "        print(f\"  ├─ Input Dimension     : {self.in_features}\")\n",
    "        print(f\"  └─ Hidden Dimension    : {self.out_features}\")\n",
    "        print(\"-\"*90)\n",
    "\n",
    "        print(\"Model Architecture:\")\n",
    "        print(\"-\" * 60)\n",
    "        for layer in self.layers:\n",
    "            layer_name = layer.__class__.__name__\n",
    "            print(f\"  └── {layer_name}()\")\n",
    "        print(\"-\" * 60)\n",
    "\n",
    "        print(f\"Total Trainable Parameters : {self.n_parameters:,}\")\n",
    "        print(\"=\"*90 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "707d4c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Define Architecture of the Neural Network: Model\n",
    "n_classes = 27\n",
    "embd_dim = 2\n",
    "block_size = 8\n",
    "in_features = block_size * embd_dim\n",
    "out_features = 8\n",
    "softmax = Softmax()\n",
    "loss_fn = CrossEntropyLoss()\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "MLP_v1 = Sequential([\n",
    "    Embeddings(n_classes = n_classes, embd_dim = embd_dim),\n",
    "    Flatten(),\n",
    "    Linear(in_features = in_features, out_features = out_features),\n",
    "    Tanh(),\n",
    "    Linear(in_features = out_features, out_features = out_features),\n",
    "    Tanh(),\n",
    "    Linear(in_features = out_features, out_features = n_classes)\n",
    "])\n",
    "\n",
    "MLP_v2 = Sequential([\n",
    "    Embeddings(n_classes = n_classes, embd_dim = embd_dim),\n",
    "    Flatten(),\n",
    "    Linear(in_features = in_features, out_features = out_features),\n",
    "    LayerNorm1d(in_features = out_features),\n",
    "    Tanh(),\n",
    "    Linear(in_features = out_features, out_features = out_features),\n",
    "    LayerNorm1d(in_features = out_features),\n",
    "    Tanh(),\n",
    "    Linear(in_features = out_features, out_features = n_classes)\n",
    "])\n",
    "\n",
    "MLP_v1.to(device)\n",
    "MLP_v2.to(device)\n",
    "\n",
    "x_train = x_train.to(device)\n",
    "y_train = y_train.to(device)\n",
    "\n",
    "# Debug\n",
    "# embeddings = Embeddings(n_classes = n_classes, embd_dim = embd_dim).to(device)\n",
    "# print(f\"x_train.shape = {x_train.shape}\")\n",
    "# x_enc = embeddings(x_train)\n",
    "# print(f\"x_enc.shape = {x_enc.shape}\")\n",
    "# flatten_layer = Flatten().to(device)\n",
    "# x_enc_flatten = flatten_layer(x_enc)\n",
    "# print(f\"x_enc_flatten.shape = {x_enc_flatten.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e74a91d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model registered with 505 Parameters\n"
     ]
    }
   ],
   "source": [
    "MultiLayerPerceptronModel_v1 = RegisterModel(model = MLP_v1, model_name = \"MultiLayerPerceptronModel_v1\", model_version = \"version-1\", device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1e2d1ff7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training MultiLayerPerceptronModel_v1 | version-1 | Epochs = 100 | lr = 0.01 | device = cuda\n",
      "\n",
      "==========================================================================================\n",
      "Training Configuration Summary\n",
      "==========================================================================================\n",
      "Model Name        : MultiLayerPerceptronModel_v1\n",
      "Model Version     : version-1\n",
      "Device            : cuda\n",
      "Epochs            : 100\n",
      "Learning Rate     : 0.01\n",
      "------------------------------------------------------------------------------------------\n",
      "Model Hyperparameters:\n",
      "  ├─ Embedding Dimension : 2\n",
      "  ├─ Number of Classes   : 27\n",
      "  ├─ Input Dimension     : 16\n",
      "  └─ Hidden Dimension    : 8\n",
      "------------------------------------------------------------------------------------------\n",
      "Model Architecture:\n",
      "------------------------------------------------------------\n",
      "  └── Embeddings()\n",
      "  └── Flatten()\n",
      "  └── Linear()\n",
      "  └── Tanh()\n",
      "  └── Linear()\n",
      "  └── Tanh()\n",
      "  └── Linear()\n",
      "------------------------------------------------------------\n",
      "Total Trainable Parameters : 505\n",
      "==========================================================================================\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch 0/100 | Loss: 4.5226 | lr=0.01000\n",
      "Epoch 50/100 | Loss: 2.6959 | lr=0.01000\n"
     ]
    }
   ],
   "source": [
    "MultiLayerPerceptronModel_v1(x = x_train, y = y_train, epochs = 100, lr = 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1cce6f5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model registered with 537 Parameters\n"
     ]
    }
   ],
   "source": [
    "MultiLayerPerceptronModel_v2 = RegisterModel(model = MLP_v2, model_name = \"MultiLayerPerceptronModel_v2\", model_version = \"version-2\", device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "090f1f6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training MultiLayerPerceptronModel_v2 | version-2 | Epochs = 100 | lr = 0.01 | device = cuda\n",
      "\n",
      "==========================================================================================\n",
      "Training Configuration Summary\n",
      "==========================================================================================\n",
      "Model Name        : MultiLayerPerceptronModel_v2\n",
      "Model Version     : version-2\n",
      "Device            : cuda\n",
      "Epochs            : 100\n",
      "Learning Rate     : 0.01\n",
      "------------------------------------------------------------------------------------------\n",
      "Model Hyperparameters:\n",
      "  ├─ Embedding Dimension : 2\n",
      "  ├─ Number of Classes   : 27\n",
      "  ├─ Input Dimension     : 16\n",
      "  └─ Hidden Dimension    : 8\n",
      "------------------------------------------------------------------------------------------\n",
      "Model Architecture:\n",
      "------------------------------------------------------------\n",
      "  └── Embeddings()\n",
      "  └── Flatten()\n",
      "  └── Linear()\n",
      "  └── LayerNorm1d()\n",
      "  └── Tanh()\n",
      "  └── Linear()\n",
      "  └── LayerNorm1d()\n",
      "  └── Tanh()\n",
      "  └── Linear()\n",
      "------------------------------------------------------------\n",
      "Total Trainable Parameters : 537\n",
      "==========================================================================================\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch 0/100 | Loss: 4.0727 | lr=0.01000\n",
      "Epoch 50/100 | Loss: 2.6615 | lr=0.01000\n"
     ]
    }
   ],
   "source": [
    "MultiLayerPerceptronModel_v2(x = x_train, y = y_train, epochs = 100, lr = 0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8019acbf",
   "metadata": {},
   "source": [
    "## Sample from the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d27f68ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_names(count: int, model, block_size: int):\n",
    "    names = []\n",
    "\n",
    "    for _ in range(count):\n",
    "        out = []\n",
    "        context = [0] * block_size\n",
    "        \n",
    "        while True:\n",
    "            x = torch.tensor([context]).to(device)\n",
    "            logits = model(x)\n",
    "\n",
    "            # Only use logits from last position (autoregressive prediction)\n",
    "            probs = softmax(logits)\n",
    "\n",
    "            idx = torch.multinomial(probs, num_samples=1).item()\n",
    "            context = context[1:] + [idx]\n",
    "\n",
    "            if idx == 0:  # end-of-word token\n",
    "                break\n",
    "\n",
    "            out.append(idx)\n",
    "\n",
    "        # Decode indices → characters\n",
    "        name = ''.join(itos[i] for i in out).capitalize()\n",
    "        names.append(name)\n",
    "\n",
    "    return names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "645c9756",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Names Generated from Model-1: ['Eomae', 'Erditen', 'Csortsney', 'Aaenzo', 'Slrre']\n",
      "Names Generated from Model-2: ['Yrcevsa', 'Broka', 'Zelarav', 'Ali', 'Arl']\n"
     ]
    }
   ],
   "source": [
    "names_v1 = generate_names(count = 5, model = MLP_v1, block_size = 8)\n",
    "names_v2 = generate_names(count = 5, model = MLP_v2, block_size = 8)\n",
    "print(f\"Names Generated from Model-1: {names_v1}\")\n",
    "print(f\"Names Generated from Model-2: {names_v2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b3aaa05c",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = Embeddings(n_classes = n_classes, embd_dim = embd_dim).to(device)\n",
    "flatten = Flatten()\n",
    "layer_1 = Linear(in_features = in_features, out_features = out_features).to(device)\n",
    "tanh = Tanh()\n",
    "layer_2 = Linear(in_features = out_features, out_features = out_features).to(device)\n",
    "tanh = Tanh()\n",
    "layer_3 = Linear(in_features = out_features, out_features = out_features).to(device)\n",
    "tanh = Tanh()\n",
    "layer_4 = Linear(in_features = out_features, out_features = n_classes).to(device)\n",
    "softmax = Softmax()\n",
    "loss_fn = CrossEntropyLoss()\n",
    "eps = 1e-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a696208a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_pass(x):\n",
    "    x = layer_1(x)\n",
    "    x = tanh(x)\n",
    "    x = layer_2(x)\n",
    "    x = layer_2(x)\n",
    "    x = tanh(x)\n",
    "    x = layer_3(x)\n",
    "    x = tanh(x)\n",
    "    x = layer_4(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "7f4f6868",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[10, 17, 24,  7, 10, 11,  7, 10]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_example = torch.randint(1, 27, size = [1, 8])\n",
    "x_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c6735ddf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 8, 2])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings(x_example).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b6ffa017",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 16])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flatten_example = flatten(embeddings(x_example))\n",
    "flatten_example.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "c83a2ec2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 27])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(forward_pass(flatten_example)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "79848169",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2, 3, 27])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(torch.randn(1, 2, 3, 16) @ torch.randn(16, 27) + torch.randn(1, 27)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d259580",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "374f08b1",
   "metadata": {},
   "source": [
    "## Loss Analysis\n",
    "\n",
    "I evaluated the impact of increasing the `block_size` from **3 → 8** on both a Plain MLP and a BatchNorm-augmented MLP.\n",
    "\n",
    "| Model             | Block Size | Train Loss | Test Loss | Val Loss |\n",
    "| ----------------- | ---------- | ---------- | --------- | -------- |\n",
    "| **Plain MLP**     | 3          | 2.0001     | 2.0939    | 2.1003   |\n",
    "| **BatchNorm MLP** | 3          | 2.0006     | 2.1040    | 2.1081   |\n",
    "| **Plain MLP**     | 8          | 1.750       | 2.051    | 2.0525   |\n",
    "| **BatchNorm MLP** | 8          | 1.8535     | 2.0409    | 2.0408   |\n",
    "\n",
    "---\n",
    "\n",
    "**Observation & Interpretation:**\n",
    "\n",
    "* Both models show reduced loss when the block size is increased.\n",
    "* **Plain MLP** achieves the largest improvement, especially in validation loss, suggesting stronger generalization.\n",
    "* **BatchNorm MLP** also benefits, though the improvements are smaller since BatchNorm already stabilizes training.\n",
    "* The results indicate that a larger block size enables the model to **capture longer-range dependencies** in the data, which enhances learning efficiency and reduces overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "159a712c",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "* To be added after implementing the WaveNet architecture."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
