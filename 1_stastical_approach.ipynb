{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e26ba9c3",
   "metadata": {},
   "source": [
    "# Generate More\n",
    "#### This Generate more is like saying, \"Make More of these that sounds like this\"\n",
    "\n",
    "- Under the hood, generate more is a character level language model\n",
    "- Character level language model means, it will predict next character based on the previous characters\n",
    "\n",
    "## Current language models are:\n",
    "- Bigrams\n",
    "- Bag of words\n",
    "- MLP\n",
    "- RNN\n",
    "- GRU\n",
    "- Transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0378dee",
   "metadata": {},
   "source": [
    "# Part-1: Stastical Approach"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aab52ba",
   "metadata": {},
   "source": [
    "### What is **Statistical Approach**\n",
    "\n",
    "1. **Character-Level Bigram Representation**:\n",
    "   The model captures dependencies between consecutive characters by constructing a bigram count matrix `N`, where each entry `N[i, j]` records how often character *j* follows character *i* in the training corpus.\n",
    "\n",
    "2. **Probability Distribution Estimation**:\n",
    "   By normalizing the bigram count matrix row-wise, we transform raw frequencies into conditional probability distributions `P(next_char | current_char)`. This represents a **maximum likelihood estimation** of the bigram probabilities.\n",
    "\n",
    "3. **Generative Process**:\n",
    "   Text generation is performed by sampling characters sequentially from the learned probability distributions using multinomial sampling, starting from a special start-of-sequence token and terminating at an end-of-sequence token.\n",
    "\n",
    "4. **Purely Statistical Nature**:\n",
    "   This approach does not involve trainable parameters or gradient-based optimization. It is purely **statistical modeling** based on co-occurrence counts from the dataset.\n",
    "\n",
    "5. **Advantages & Limitations**:\n",
    "\n",
    "   * Advantage: Simple, interpretable, and directly based on corpus statistics.\n",
    "   * Limitation: Cannot generalize beyond observed bigrams; lacks the ability to capture higher-order dependencies or semantic structure.\n",
    "\n",
    "6. **Baseline for Neural Models**:\n",
    "   The statistical bigram model provides a foundational baseline. It highlights the limitations of count-based approaches, motivating the shift toward **neural network-based language models** that learn distributed representations and optimize via loss functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2abbc9fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataset\n",
    "words = open('names.txt', 'r').read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7ccde0d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['emma', 'olivia', 'ava', 'isabella', 'sophia', 'charlotte', 'mia', 'amelia', 'harper', 'evelyn']\n"
     ]
    }
   ],
   "source": [
    "print(words[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "277ca4a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32033"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fc56ba78",
   "metadata": {},
   "outputs": [],
   "source": [
    "biagram_count = dict()\n",
    "for w in words:\n",
    "    chars = [\"<S>\"] + list(w) + [\"<E>\"]\n",
    "    for ch1, ch2 in zip(chars, chars[1:]):\n",
    "        bigram = (ch1, ch2)\n",
    "        biagram_count[bigram] = biagram_count.get(bigram, 0) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7b674f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6448cf9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = torch.zeros((27, 27), dtype=torch.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6796d8cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = sorted(list(set(''.join(words))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2b8976bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "stoi = {s:i+1 for i, s in enumerate(chars)}\n",
    "stoi['.'] = 0\n",
    "itos = {i:s for s, i in stoi.items()}\n",
    "\n",
    "# stoi = StringToInteger\n",
    "# itos = IntegerToString"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6cf05aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for w in words:\n",
    "    chars = [\".\"] + list(w) + [\".\"]\n",
    "    for ch1, ch2 in zip(chars, chars[1:]):\n",
    "        idx1 = stoi[ch1]\n",
    "        idx2 = stoi[ch2]\n",
    "        N[idx1, idx2] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da32ffed",
   "metadata": {},
   "source": [
    "## Visualizing the Bigram Count Tensor\n",
    "\n",
    "* I’ve created a tensor that represents the frequency of word pairings. For example, if the bigram is `'ab'`, the tensor shows how many times `'b'` follows `'a'` in our corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "11c95062",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2597ea11180>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f110536",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.5, 26.5, 26.5, -0.5)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.figure(figsize=(16, 16))\n",
    "plt.imshow(N, cmap='Blues')\n",
    "for i in range(27):\n",
    "    for j in range(27):\n",
    "        chars = itos[i] + itos[j]\n",
    "        plt.text(j, i, chars, ha = 'center', va = 'bottom')\n",
    "        plt.text(j, i, N[i, j].item(), ha = 'center', va = 'top')\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f337bb23",
   "metadata": {},
   "source": [
    "## Random garbage results of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86d17a8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yeosyohlvfbgqqdlxgktsmzmgwnyb.\n",
      "tryvwdxchwndenbedlppmjiaeqybkejmszqsqgtoyzjovtkimpupooznnyzujfosjvslrumxtonaclpgcyaqxknvzioiuqrtensqvgsumjqwqeioionyyrmnyctrjzdwtyazxdbpnftaauzyskakoth.\n",
      "eyumwlni.\n",
      "zripawaejtxpoxkelygylxsqfdcnidebwfmbiaaewbtorpaclulyaixbxsmpsvqccgkmbr.\n",
      "bcqfmfdvushlqqaspiaycg.\n"
     ]
    }
   ],
   "source": [
    "generator = torch.Generator().manual_seed(42)\n",
    "\n",
    "for i in range(5):\n",
    "    idx = 0\n",
    "    while True:\n",
    "        p = torch.ones(27)\n",
    "        p = p / p.sum()\n",
    "        idx = torch.multinomial(p, num_samples=1, generator=generator, replacement=True).item()\n",
    "        print(''.join(itos[idx]), end = '')\n",
    "        if idx == 0:\n",
    "            break\n",
    "    \n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edc03bd7",
   "metadata": {},
   "source": [
    "## Producing Initial Words from the Statistical Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a9d0ad5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ynelinarahuminn.\n",
      "mexa.\n",
      "r.\n",
      "blesonshlladiyn.\n",
      "leeieloteeceniabanailianavar.\n",
      "ayn.\n",
      "adena.\n",
      "id.\n",
      "hangllie.\n",
      "n.\n",
      "meela.\n",
      "ja.\n",
      "joy.\n",
      "kly.\n",
      "jonlizas.\n",
      "onassa.\n",
      "era.\n",
      "a.\n",
      "ahyamusali.\n",
      "iemronayoh.\n"
     ]
    }
   ],
   "source": [
    "P = N.float()\n",
    "P /= P.sum(dim=1, keepdim=True)\n",
    "\n",
    "# Setting up the generator\n",
    "generator = torch.Generator().manual_seed(42)\n",
    "for i in range(20):\n",
    "    idx = 0\n",
    "    while True:\n",
    "        p = P[idx]\n",
    "        idx = torch.multinomial(p, num_samples=1, replacement=True).item()\n",
    "        print(''.join(itos[idx]), end = '')\n",
    "        if idx == 0:\n",
    "            break\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7554746a",
   "metadata": {},
   "source": [
    "## **Conclusion:**\n",
    "* I trained a bigram language model based purely on statistical analysis of word occurrences and bigram counts.\n",
    "* Although the model’s output doesn’t produce meaningful words, it still performs better than completely random results.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35caaaa9",
   "metadata": {},
   "source": [
    "## Now, let’s evaluate our model’s performance by examining its loss.\n",
    "\n",
    "**Goal:**\n",
    "1. Maximize the likelihood of the data with respect to the model’s parameters (statistical modeling).\n",
    "2. This is equivalent to maximizing the log-likelihood.\n",
    "3. Which, in turn, is equivalent to minimizing the negative log-likelihood.\n",
    "4. Finally, this reduces to minimizing the average negative log-likelihood.\n",
    "\n",
    "### Conclusion: \n",
    "- These optimization formulations are mathematically equivalent representations of the same objective.\n",
    "- Incorporating the loss function allows us to quantify the quality of our model’s predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff736ea1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log likelihood = -559891.75\n",
      "negavtive log likelihood (Loss Function) = 559891.7500\n",
      "Average of negative log likelihood = 2.4541\n"
     ]
    }
   ],
   "source": [
    "log_likelihood = 0.0\n",
    "n = 0\n",
    "for w in words:\n",
    "    chars = ['.'] + list(w) + ['.']\n",
    "    for ch1, ch2 in zip(chars, chars[1:]):\n",
    "        bigram = (ch1, ch2) \n",
    "        idx1 = stoi[ch1]\n",
    "        idx2 = stoi[ch2]\n",
    "        prob = P[idx1, idx2]\n",
    "        logprob = torch.log(prob)\n",
    "        log_likelihood += logprob\n",
    "        negative_log_likelihood = -log_likelihood\n",
    "        n += 1\n",
    "        # print(f\"P({bigram}) = {prob:.4f} | logprob = {logprob:.4f}\") # for better log\n",
    "\n",
    "print(f\"log likelihood = {log_likelihood}\")\n",
    "print(f\"negavtive log likelihood (Loss Function) = {(negative_log_likelihood):.4f}\")\n",
    "avg_statical_loss = negative_log_likelihood/n\n",
    "print(f\"Average of negative log likelihood = {avg_statical_loss:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
